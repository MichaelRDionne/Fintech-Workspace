{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the CSV file path\n",
    "file_path = Path(\"../01_Creating_Deep_Learning_Models_with_Keras/wine_quality.csv\")\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display sample data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features (X) and target (y) sets\n",
    "X = df.drop(columns=[\"quality\"]).values\n",
    "y = df[\"quality\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Create the StandardScaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 19:51:43.732397: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-05 19:51:43.732520: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net with 2 hidden layers\n",
    "number_input_features = 11\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 = 4\n",
    "\n",
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(Dense(units=1, activation=\"linear\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 19:54:04.453084: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-09-05 19:54:04.621636: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 10ms/step - loss: 35.7648 - mse: 35.7648\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 30.4840 - mse: 30.4840\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 25.2372 - mse: 25.2372\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 19.5304 - mse: 19.5304\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 14.3296 - mse: 14.3296\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 10.2802 - mse: 10.2802\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 7.4377 - mse: 7.4377\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 5.5945 - mse: 5.5945\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 4.3791 - mse: 4.3791\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 3.6190 - mse: 3.6190\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 3.1282 - mse: 3.1282\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.7811 - mse: 2.7811\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.5283 - mse: 2.5283\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.3307 - mse: 2.3307\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.1699 - mse: 2.1699\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.0328 - mse: 2.0328\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.9162 - mse: 1.9162\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.8159 - mse: 1.8159\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.7208 - mse: 1.7208\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.6382 - mse: 1.6382\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5612 - mse: 1.5612\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.4924 - mse: 1.4924\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.4281 - mse: 1.4281\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3698 - mse: 1.3698\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3155 - mse: 1.3155\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2599 - mse: 1.2599\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2086 - mse: 1.2086\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1592 - mse: 1.1592\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1158 - mse: 1.1158\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0728 - mse: 1.0728\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0312 - mse: 1.0312\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9951 - mse: 0.9951\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9579 - mse: 0.9579\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9263 - mse: 0.9263\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8922 - mse: 0.8922\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8581 - mse: 0.8581\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8270 - mse: 0.8270\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7961 - mse: 0.7961\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7685 - mse: 0.7685\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7432 - mse: 0.7432\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7185 - mse: 0.7185\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6974 - mse: 0.6974\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6773 - mse: 0.6773\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6556 - mse: 0.6556\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6382 - mse: 0.6382\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6211 - mse: 0.6211\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6045 - mse: 0.6045\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5895 - mse: 0.5895\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5771 - mse: 0.5771\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5630 - mse: 0.5630\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5517 - mse: 0.5517\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5402 - mse: 0.5402\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5310 - mse: 0.5310\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5201 - mse: 0.5201\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5133 - mse: 0.5133\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5067 - mse: 0.5067\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4993 - mse: 0.4993\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4921 - mse: 0.4921\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4881 - mse: 0.4881\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4818 - mse: 0.4818\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4768 - mse: 0.4768\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4710 - mse: 0.4710\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4673 - mse: 0.4673\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4627 - mse: 0.4627\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4582 - mse: 0.4582\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4562 - mse: 0.4562\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4524 - mse: 0.4524\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4480 - mse: 0.4480\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4439 - mse: 0.4439\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4428 - mse: 0.4428\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4402 - mse: 0.4402\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4363 - mse: 0.4363\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4335 - mse: 0.4335\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4320 - mse: 0.4320\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4283 - mse: 0.4283\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4268 - mse: 0.4268\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4246 - mse: 0.4246\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4238 - mse: 0.4238\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4218 - mse: 0.4218\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4180 - mse: 0.4180\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4160 - mse: 0.4160\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4149 - mse: 0.4149\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4114 - mse: 0.4114\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4110 - mse: 0.4110\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4106 - mse: 0.4106\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4103 - mse: 0.4103\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4075 - mse: 0.4075\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4060 - mse: 0.4060\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4038 - mse: 0.4038\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4040 - mse: 0.4040\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4011 - mse: 0.4011\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4022 - mse: 0.4022\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3992 - mse: 0.3992\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3998 - mse: 0.3998\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4001 - mse: 0.4001\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3987 - mse: 0.3987\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3992 - mse: 0.3992\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3963 - mse: 0.3963\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3946 - mse: 0.3946\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3955 - mse: 0.3955\n"
     ]
    }
   ],
   "source": [
    "# Compile the Sequential model \n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 19:58:07.818508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 16ms/step - loss: 20.2919 - mse: 20.2919\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 10.4673 - mse: 10.4673\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 5.4984 - mse: 5.4984\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 4.0633 - mse: 4.0633\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 3.4709 - mse: 3.4709\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 3.0277 - mse: 3.0277\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.6761 - mse: 2.6761\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.4037 - mse: 2.4037\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.1896 - mse: 2.1896\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9864 - mse: 1.9864\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.8267 - mse: 1.8267\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.6878 - mse: 1.6878\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5565 - mse: 1.5565\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.4440 - mse: 1.4440\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3347 - mse: 1.3347\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2441 - mse: 1.2441\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1602 - mse: 1.1602\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0855 - mse: 1.0855\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0201 - mse: 1.0201\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9583 - mse: 0.9583\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9022 - mse: 0.9022\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8604 - mse: 0.8604\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8163 - mse: 0.8163\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7757 - mse: 0.7757\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7406 - mse: 0.7406\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7090 - mse: 0.7090\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6858 - mse: 0.6858\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6606 - mse: 0.6606\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6384 - mse: 0.6384\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6190 - mse: 0.6190\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6022 - mse: 0.6022\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5823 - mse: 0.5823\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5673 - mse: 0.5673\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5481 - mse: 0.5481\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5364 - mse: 0.5364\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5247 - mse: 0.5247\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5148 - mse: 0.5148\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5055 - mse: 0.5055\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4925 - mse: 0.4925\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4856 - mse: 0.4856\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4816 - mse: 0.4816\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4710 - mse: 0.4710\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4626 - mse: 0.4626\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4614 - mse: 0.4614\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4526 - mse: 0.4526\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4512 - mse: 0.4512\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4426 - mse: 0.4426\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4416 - mse: 0.4416\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4343 - mse: 0.4343\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4307 - mse: 0.4307\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4268 - mse: 0.4268\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4237 - mse: 0.4237\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4241 - mse: 0.4241\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4205 - mse: 0.4205\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4120 - mse: 0.4120\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4162 - mse: 0.4162\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4100 - mse: 0.4100\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4104 - mse: 0.4104\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4054 - mse: 0.4054\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4069 - mse: 0.4069\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4010 - mse: 0.4010\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4048 - mse: 0.4048\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3977 - mse: 0.3977\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3997 - mse: 0.3997\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3942 - mse: 0.3942\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3902 - mse: 0.3902\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3918 - mse: 0.3918\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3914 - mse: 0.3914\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3847 - mse: 0.3847\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3877 - mse: 0.3877\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3857 - mse: 0.3857\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3835 - mse: 0.3835\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3829 - mse: 0.3829\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3793 - mse: 0.3793\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3777 - mse: 0.3777\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3839 - mse: 0.3839\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3734 - mse: 0.3734\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3753 - mse: 0.3753\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3730 - mse: 0.3730\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3688 - mse: 0.3688\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3739 - mse: 0.3739\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3670 - mse: 0.3670\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3671 - mse: 0.3671\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3638 - mse: 0.3638\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3635 - mse: 0.3635\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3657 - mse: 0.3657\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3657 - mse: 0.3657\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3625 - mse: 0.3625\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3585 - mse: 0.3585\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3641 - mse: 0.3641\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3555 - mse: 0.3555\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3583 - mse: 0.3583\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3588 - mse: 0.3588\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3570 - mse: 0.3570\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3545 - mse: 0.3545\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3508 - mse: 0.3508\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3483 - mse: 0.3483\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3530 - mse: 0.3530\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3499 - mse: 0.3499\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3496 - mse: 0.3496\n"
     ]
    }
   ],
   "source": [
    "#Define the model - deep neural net with 2 hidden layers\n",
    "number_input_features = 11\n",
    "hidden_nodes_layer1 = 22\n",
    "hidden_nodes_layer2 = 11\n",
    "\n",
    "# Create the Sequential neural model instance\n",
    "nn_1 = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_1.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_1.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_1.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Compile the Sequential model\n",
    "nn_1.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "model_1 = nn_1.fit(X_train_scaled, y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 19:58:36.734760: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 6ms/step - loss: 25.5636 - mse: 25.5636\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 13.7684 - mse: 13.7684\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 6.6415 - mse: 6.6415\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 3.7169 - mse: 3.7169\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.7336 - mse: 2.7336\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.2363 - mse: 2.2363\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9082 - mse: 1.9082\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.6838 - mse: 1.6838\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5205 - mse: 1.5205\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3926 - mse: 1.3926\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2860 - mse: 1.2860\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1982 - mse: 1.1982\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1175 - mse: 1.1175\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0449 - mse: 1.0449\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9810 - mse: 0.9810\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9185 - mse: 0.9185\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8641 - mse: 0.8641\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8153 - mse: 0.8153\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7711 - mse: 0.7711\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7342 - mse: 0.7342\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6975 - mse: 0.6975\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6645 - mse: 0.6645\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6384 - mse: 0.6384\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6113 - mse: 0.6113\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5817 - mse: 0.5817\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5634 - mse: 0.5634\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5466 - mse: 0.5466\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5273 - mse: 0.5273\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5119 - mse: 0.5119\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4985 - mse: 0.4985\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4902 - mse: 0.4902\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4756 - mse: 0.4756\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4646 - mse: 0.4646\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4591 - mse: 0.4591\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4488 - mse: 0.4488\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4411 - mse: 0.4411\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4355 - mse: 0.4355\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4299 - mse: 0.4299\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4244 - mse: 0.4244\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4181 - mse: 0.4181\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4105 - mse: 0.4105\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4102 - mse: 0.4102\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4044 - mse: 0.4044\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4021 - mse: 0.4021\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3963 - mse: 0.3963\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3951 - mse: 0.3951\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3878 - mse: 0.3878\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3850 - mse: 0.3850\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3800 - mse: 0.3800\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3776 - mse: 0.3776\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3764 - mse: 0.3764\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3728 - mse: 0.3728\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3714 - mse: 0.3714\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3670 - mse: 0.3670\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3625 - mse: 0.3625\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3631 - mse: 0.3631\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3611 - mse: 0.3611\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3602 - mse: 0.3602\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3567 - mse: 0.3567\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3550 - mse: 0.3550\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3529 - mse: 0.3529\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3525 - mse: 0.3525\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3503 - mse: 0.3503\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3437 - mse: 0.3437\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3461 - mse: 0.3461\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3472 - mse: 0.3472\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3413 - mse: 0.3413\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3387 - mse: 0.3387\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3381 - mse: 0.3381\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3438 - mse: 0.3438\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3398 - mse: 0.3398\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3396 - mse: 0.3396\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3325 - mse: 0.3325\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3335 - mse: 0.3335\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3292 - mse: 0.3292\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3285 - mse: 0.3285\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3290 - mse: 0.3290\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3247 - mse: 0.3247\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3275 - mse: 0.3275\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3296 - mse: 0.3296\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3254 - mse: 0.3254\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3266 - mse: 0.3266\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3247 - mse: 0.3247\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3294 - mse: 0.3294\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3198 - mse: 0.3198\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3209 - mse: 0.3209\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3250 - mse: 0.3250\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3212 - mse: 0.3212\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3149 - mse: 0.3149\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3174 - mse: 0.3174\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3183 - mse: 0.3183\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3139 - mse: 0.3139\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3154 - mse: 0.3154\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3166 - mse: 0.3166\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3077 - mse: 0.3077\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3129 - mse: 0.3129\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3093 - mse: 0.3093\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3137 - mse: 0.3137\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3090 - mse: 0.3090\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3121 - mse: 0.3121\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net with two hidden layers\n",
    "number_input_features = 11\n",
    "hidden_nodes_layer1 = 22\n",
    "hidden_nodes_layer2 = 11\n",
    "hidden_nodes_layer3 = 8\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_2 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_2.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_2.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Add the third hidden layer\n",
    "nn_2.add(Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer\n",
    "nn_2.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Compile the model\n",
    "nn_2.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_model_2 = nn_2.fit(X_train_scaled, y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 0.4642 - mse: 0.4642 - 132ms/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 20:00:08.920638: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-05 20:00:09.059032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 0.4387 - mse: 0.4387 - 116ms/epoch - 9ms/step\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model 1 using the test data\n",
    "model1_loss, model1_mse = nn_1.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "\n",
    "#Evaluate the model 2 using the test data\n",
    "model2_loss, model2_mse = nn_2.evaluate(X_test_scaled,y_test,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
